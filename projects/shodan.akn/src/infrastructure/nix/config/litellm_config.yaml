model_list:
  # Ton serveur LM Studio (déjà compatible OpenAI)
  - model_name: gpt-3.5-turbo # On fait croire à LiteLLM que c'est GPT pour la compatibilité
    litellm_params:
      model: openai/local
      api_base: http://localhost:1234/v1 # Port modifié pour correspondre au daemon
      api_key: "lm-studio"

  # Ton serveur Kokoro-Fast pour le TTS
  - model_name: kokoro
    litellm_params:
      model: openai/kokoro
      api_base: http://localhost:8888/v1
      api_key: "not-needed"

router_settings:
  routing_strategy: simple-shuffle
